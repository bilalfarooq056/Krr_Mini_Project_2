

---

# ğŸ§  Knowledge Representation & Reasoning (KRR) â€” Mini Project 2

### **Topic:** *Cultural Differences in Pakistan*

### **Phases:** NER â†’ Ontology â†’ Jena â†’ Python Interface â†’ Streamlit GUI

---

## ğŸ“š Overview

This project aims to represent knowledge about **Cultural Differences in Pakistan** using Semantic Web technologies.
It provides a complete pipeline starting from **Named Entity Recognition (NER)** â†’ **Ontology Modeling** â†’ **Apache Jena Fuseki SPARQL querying** â†’ **Python/Streamlit GUI interface**.

---

# ğŸ“‚ Project Structure (Based on ZIP)

```
Mini_project_2/
â”‚
â”œâ”€â”€ entities_extracted.csv
â”œâ”€â”€ entities.csv
â”œâ”€â”€ triples.csv
â”œâ”€â”€ triples.ttl
â”‚
â”œâ”€â”€ cultural_difference_properties.ttl
â”œâ”€â”€ culturaldifference_enriched.ttl
â”œâ”€â”€ culture.rdf
â”‚
â”œâ”€â”€ queries.txt
â”œâ”€â”€ insert query(culture).txt
â”œâ”€â”€ jena running code.txt
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ Mini_project_2_all_phases.ipynb
â”‚
â””â”€â”€ README.md (this file)
```

---

# ğŸ—ï¸ Phase 1 â€” Named Entity Recognition (NER)

### âœ”ï¸ Description

Extract cultural entities from text (spaCy) and convert them into RDF triples.

### ğŸ“Œ Files

* `entities_extracted.csv`
* `entities.csv`
* `triples.csv`
* `triples.ttl`
* Code: *inside* `Mini_project_2_all_phases.ipynb`

### ğŸ“Œ Output

* Cleaned NER results
* RDF triples in Turtle format

---

# ğŸ§± Phase 2 â€” Ontology Design (ProtÃ©gÃ©)

### âœ”ï¸ Description

Design domain ontology for cultural differences in Pakistan.

### ğŸ“Œ Files

* `cultural_difference_properties.ttl`
* `culturaldifference_enriched.ttl`
* `culture.rdf`
* `triples.ttl`

### ğŸ“Œ Modeling

* Classes: Person, CulturalGroup, Religion, Language, Festival, Organization, Location
* Object properties: speaksLanguage, celebratesFestival, follows, locatedIn
* Data properties: hasName, hasDescription, hasContextSentence

---

# ğŸ§® Phase 3 â€” Apache Jena Fuseki SPARQL Server

### âœ”ï¸ Description

Load ontology and RDF data into Fuseki for querying.

### ğŸ“Œ Files

* `jena running code.txt`
* `queries.txt`
* `insert query(culture).txt`

### ğŸ“Œ Steps

1. Download Apache Jena Fuseki

2. Run server:

   ```bash
   fuseki-server
   ```

3. Open:
   [http://localhost:3030/](http://localhost:3030/)

4. Create dataset

5. Upload:

   * `triples.ttl`
   * `cultural_difference_properties.ttl`
   * `culturaldifference_enriched.ttl`
   * `culture.rdf` (optional RDF/XML)

### ğŸ“Œ Example SPARQL Query

```sparql
PREFIX : <http://example.org/culturaldifference#>
SELECT ?person ?lang WHERE {
    ?person a :Person ;
            :speaksLanguage ?lang .
}
```

---

# ğŸ Phase 4 â€” Python + Streamlit GUI Interface

### âœ”ï¸ Description

A simple GUI to test SPARQL queries on the Fuseki server.

### ğŸ“Œ Files

* `app.py`

### ğŸ“Œ Requirements

Install dependencies (Windows/Linux/Mac):

```bash
pip install streamlit SPARQLWrapper
```

### ğŸ“Œ Run GUI

```bash
streamlit run app.py
```

---

# ğŸš€ Features

* âœ”ï¸ Fully automated entity extraction
* âœ”ï¸ Complete domain ontology
* âœ”ï¸ Jena Fuseki SPARQL endpoint
* âœ”ï¸ Ready-to-use Streamlit GUI
* âœ”ï¸ Works with real cultural data for Pakistan

---

# ğŸ§© Architecture Diagram

```
Text Source
    â†“
[Phase 1] NER Extraction (spaCy)
    â†“
triples.ttl + entities.csv
    â†“
[Phase 2] Ontology Modeling (ProtÃ©gÃ©)
    â†“
Ontology + Properties + Enriched TTL
    â†“
[Phase 3] Apache Jena Fuseki
    â†“
[Phase 4] Streamlit GUI (Python)
```

---

# ğŸ§‘â€ğŸ¤â€ğŸ§‘ Contributors

| Name                 | Role                   |
| -------------------- | ---------------------- |
| **Bilal Farooq**     | Ontology Design        |
| **Alam Zeb**         | Ontology Design        |
| **Saad Khan**        | Jena Fuseki Setup      |
| **Washam Bin Adnan** | Python Interface + GUI |

---

# ğŸ Final Notes

* Always ensure your namespaces remain consistent:
  `http://example.org/culturaldifference#`
* Validate all TTL / OWL files using ProtÃ©gÃ© before loading into Fuseki.
* GUI requires a running Fuseki SPARQL endpoint.

---


Just tell me!
